
=== Importer

ArcadeDB is able to import automatically any dataset in the following formats:

- XML
- JSON
- CSV
- RDF

From file of types:

- Plain text
- Compressed with ZIP
- Compressed with GZip

Located on:

- local file system (just provide the path)
- and remote, by specifying `http` or `https`

To start importing it's super easy as providing the URL where the source file to import is located. URLs can be local paths or from the Internet by using `http` and `https`.

Example of loading the Freebase RDF dataset:

```
~/arcadedb $ cd bin
~/arcadedb/bin $ ./importer.sh -url http://commondatastorage.googleapis.com/freebase-public/rdf/freebase-rdf-latest.gz?

Analyzing url: http://commondatastorage.googleapis.com/freebase-public/rdf/freebase-rdf-latest.gz?... [SourceDiscovery]
Recognized format RDF (limitBytes=9.54MB limitEntries=0) [SourceDiscovery]
Creating type 'Node' of type VERTEX [Importer]
Creating type 'Relationship' of type EDGE [Importer]
Parsed 144951 (28990/sec) - 0 documents (0/sec) - 143055 vertices (28611/sec) - 144951 edges (28990/sec) [Importer]
Parsed 362000 (54256/sec) - 0 documents (0/sec) - 164118 vertices (5260/sec) - 362000 edges (54256/sec) [Importer]
...
```

If not specified, a database will be created under the "databases" directory, with name "imported". You can specify your own database (if existent) or the name of the new database must be created if not present:

Example of loading the Discogs dataset in the database on path "/temp/discogs":

```
~/arcadedb/bin $ ./importer.sh -database /temp/discogs -url https://discogs-data.s3-us-west-2.amazonaws.com/data/2018/discogs_20180901_releases.xml.gz
```

Note that in this case the URL is `https` and the file is compressed with `GZip`.

Example of importing New York Taxi dataset in CSV format. The first line of the CSV file set the property names:

```
~/arcadedb/bin $ ./importer.sh -database /temp/nytaxi -url /personal/Downloads/data-society-uber-pickups-in-nyc/original/uber-raw-data-april-15.csv/uber-raw-data-april-15.csv
```


==== Configuration

- `url` as the URL to import. URLs can be local paths or from the Internet by using `http` and `https`
- `database` as the database path/name to create (default=databases/imported)
- `forceDatabaseCreate` if the database doesn't exists it's created automatically (default=false)
- `commitEvery` specifies the number of operations in a batch transaction. Higher is better, but too high can consume too much RAM and increase the pressure of the JVM GC  (default=1,000)
- `parallel' specifies the number of parallel threads that execute the import.  (default=the available cores)
- `documentType` specifies the document type name to use during importing (default=Document)
- `vertexType` specifies the vertex type name to use during importing (default=Node)
- `edgeType` specifies the edge type name to use during importing (default=Relationship)
- `id` specifies the property that works as `id` (default=null)
- `idUnique` specifies if the property id is unique. (default=false)
- `idType` specifies the type of the property id. (default=String)
- `trimText` specifies if the imported text fields must be trimmed (removing leading and tailing spaces). (default=true)
- `limitBytes` specifies the maximum bytes to read from the input source. (default=0 -> unlimited)
- `limitEntries` specifies the maximum number of lines to read from the input source. (default=0 -> unlimited)
