
=== High Availability

ArcadeDB supports a High Availability mode where multiple servers share the same database (replication).

To start ArcadeDB Server in High Availability (HA) mode, modify the default setting <<#_settings,`ha.enabled`>> to `true`. Example:

```
~/arcadedb $ cd bin
~/arcadedb/bin $ ./server.sh -Darcadedb.ha.enabled=true

<ArcadeDB_0> Starting ArcadeDB Server... [ArcadeDBServer]
<ArcadeDB_0> - JMX Metrics Started... [ArcadeDBServer]
<ArcadeDB_0> - Starting HTTP Server (host=0.0.0.0 port=2480)... [HttpServer]
XNIO version 3.3.8.Final [xnio]
XNIO NIO Implementation Version 3.3.8.Final [nio]
<ArcadeDB_0> - HTTP Server started (host=0.0.0.0 port=2480) [HttpServer]
<ArcadeDB_0> Listening Replication connections on 127.0.0.1:2424 (protocol v.-1) [LeaderNetworkListener]
<ArcadeDB_0> Unable to find any Leader, start election (cluster=arcadedb configuredServers=1 majorityOfVotes=1) [HAServer]
<ArcadeDB_0> Change election status from DONE to VOTING_FOR_ME [HAServer]
<ArcadeDB_0> ArcadeDB Server started (CPUs=8 MAXRAM=1.92GB) [ArcadeDBServer]
<ArcadeDB_0> Starting election of local server asking for votes from [] (turn=1 retry=0 lastReplicationMessage=-1 configuredServers=1 majorityOfVotes=1) [HAServer]
<ArcadeDB_0> Current server elected as new Leader (turn=1 totalVotes=1 majority=1) [HAServer]
<ArcadeDB_0> Change election status from VOTING_FOR_ME to LEADER_WAITING_FOR_QUORUM [HAServer]
<ArcadeDB_0> Contacting all the servers for the new leadership (turn=1)... [HAServer]
```

==== Architecture

ArcadeDB has a Leader/Replica model by using RAFT consensus for election and replication.

[ditaa,ha-architecture]
....
 +------------+        +------------+        +------------+
 | ArcadeDB_1 |<-------| ArcadeDB_0 |------->| ArcadeDB_2 |
 |  Replica   |        |   Leader   |        |  Replica   |
 +------------+        +------------+        +------------+
       |                     |                     |
       |                     |                     |
       V                     V                     V
  +----------+          +----------+          +----------+
  |   WAL    |          |   WAL    |          |   WAL    |
  |      {d} |          |      {d} |          |      {d} |
  +----------+          +----------+          +----------+

....


More coming soon.

==== Starting multiple servers in cluster

More coming soon.

==== Auto fail-over

More coming soon.

==== Auto balancing of the clients

More coming soon.

==== Kubernates (K8S)

In order to scale up or down with the number of replicas, use this:

```
kubectl scale statefulsets arcadedb-server --replicas=<new-number-of-replicas>
```

Where the value of `<new-number-of-replicas>` is the new number of replicas. Example:

```
kubectl scale statefulsets arcadedb-server --replicas=3
```

Scaling up and down doesn't affect current workload. There are no pauses when a server enters/exits from the cluster.

More coming soon.
