[[java-vectors]]
==== Working with Vector Embeddings

ArcadeDB provides robust support for vector embeddings through the LSMVectorIndex, a persistent vector index built on ArcadeDB's LSM Tree architecture and powered by the JVector 4.0.0 library. LSMVectorIndex offers efficient storage, retrieval, and similarity search for vector embeddings with full transaction support and automatic persistence.

===== Key Features

The LSMVectorIndex implementation provides:

- *Persistent Storage*: Vector indexes are stored on disk with automatic page management and compaction
- *Transaction Support*: Full ACID compliance with automatic persistence on transaction commit
- *Multiple Similarity Functions*: Supports COSINE (default), DOT_PRODUCT, and EUCLIDEAN distance metrics
- *SQL Integration*: Create and query vector indexes using SQL commands
- *Automatic Compaction*: Efficiently reclaims disk space through automatic compaction of immutable pages
- *High Performance*: Leverages LSM Tree benefits for write efficiency and space optimization at scale
- *Configurable Parameters*: Tune maxConnections and beamWidth for optimal ANN search performance
- *JVector Library*: Built on JVector 4.0.0 for state-of-the-art vector search capabilities

===== Creating Vector Indexes with SQL

The simplest way to create a vector index is through SQL. This approach is recommended for most use cases as it provides a declarative syntax and automatic schema management.

====== Basic Vector Index Creation

Create a basic LSMVectorIndex for similarity search:

[source,sql]
----
-- Create vertex type and property
CREATE VERTEX TYPE Document;
CREATE PROPERTY Document.embedding LIST OF FLOAT;

-- Create vector index with 384 dimensions using COSINE similarity
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 384,
  "similarity": "COSINE"
};
----

====== Configuring Similarity Functions

Choose the appropriate similarity function for your use case:

*COSINE Similarity* (default) - Best for normalized vectors, commonly used with text embeddings:

[source,sql]
----
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 768,
  "similarity": "COSINE"
};
----

*DOT_PRODUCT* - Efficient for normalized vectors, faster than cosine:

[source,sql]
----
CREATE INDEX ON Image (featureVector) LSM_VECTOR METADATA {
  "dimensions": 512,
  "similarity": "DOT_PRODUCT"
};
----

*EUCLIDEAN* - Measures absolute distance, useful for spatial data:

[source,sql]
----
CREATE INDEX ON Product (attributes) LSM_VECTOR METADATA {
  "dimensions": 256,
  "similarity": "EUCLIDEAN"
};
----

====== Performance Tuning Parameters

For large-scale deployments, tune performance parameters:

[source,sql]
----
CREATE INDEX ON VectorVertex (embedding) LSM_VECTOR METADATA {
  "dimensions": 1024,
  "similarity": "COSINE",
  "maxConnections": 32,              -- Higher values improve recall but increase memory
  "beamWidth": 200,                  -- Higher values improve accuracy but reduce speed
  "neighborOverflowFactor": 1.2,     -- Candidate neighbor pool multiplier (default: 1.2)
  "alphaDiversityRelaxation": 1.2    -- Diversity vs distance trade-off (default: 1.2)
};
----

*Parameter Guidelines:*

- `dimensions`: Must match your embedding model's output dimension (required)
- `similarity`: Choose based on your embedding model and use case (default: COSINE)
- `maxConnections`: Maximum connections per node in HNSW graph (default: 16). Increase to 32-48 for better recall in large datasets
- `beamWidth`: Search depth during index construction (default: 100). Increase to 200-400 for more accurate searches
- `neighborOverflowFactor`: Controls how many extra candidate neighbors are considered during graph building (default: 1.2, range: 1.0-1.5). Higher values improve graph quality but increase build time
- `alphaDiversityRelaxation`: Trade-off between strict distance ordering and diversity in graph connections (default: 1.2, range: 1.0-1.5). Higher values prioritize diversity, improving recall for complex queries

====== Advanced Tuning Profiles

*Default Configuration* (recommended for most use cases):

[source,sql]
----
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 768,
  "similarity": "COSINE",
  "maxConnections": 16,
  "beamWidth": 100,
  "neighborOverflowFactor": 1.2,
  "alphaDiversityRelaxation": 1.2
};
----

*High Recall Configuration* (accuracy-critical applications):

[source,sql]
----
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 768,
  "similarity": "COSINE",
  "maxConnections": 32,
  "beamWidth": 200,
  "neighborOverflowFactor": 1.4,
  "alphaDiversityRelaxation": 1.3
};
----

This configuration provides ~98% recall@10 but requires 2-3x longer build time and ~50% more memory.

*Fast Indexing Configuration* (real-time ingestion, large-scale ETL):

[source,sql]
----
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 768,
  "similarity": "COSINE",
  "maxConnections": 12,
  "beamWidth": 80,
  "neighborOverflowFactor": 1.1,
  "alphaDiversityRelaxation": 1.1
};
----

This configuration provides 2x faster indexing with 5-10% lower recall.

*Memory Constrained Configuration* (edge deployments, resource-limited servers):

[source,sql]
----
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 768,
  "similarity": "COSINE",
  "maxConnections": 8,
  "beamWidth": 100,
  "neighborOverflowFactor": 1.2,
  "alphaDiversityRelaxation": 1.2
};
----

This configuration reduces memory usage while maintaining acceptable recall

===== Memory and Performance Tuning

ArcadeDB provides three global configuration settings to control memory consumption and performance of LSM Vector indexes. These settings can be configured globally via database settings or per-index through metadata.

====== Configuration Parameters

*Location Cache Size* (`locationCacheSize`)

Controls the maximum number of vector location metadata entries cached in memory. Each entry uses approximately 56 bytes.

- *Default*: `-1` (unlimited, backward compatible)
- *Per-index metadata*: `"locationCacheSize": 100000`
- *Global setting*: `arcadedb.vectorIndex.locationCacheSize`
- *Recommended*: 100,000 for datasets with 1M+ vectors (~5.6 MB RAM)

*Graph Build Cache Size* (`graphBuildCacheSize`)

Controls the maximum number of vectors cached during HNSW graph construction. RAM usage = `cacheSize × (dimensions × 4 + 64)` bytes.

- *Default*: `10000` (bounded cache)
- *Per-index metadata*: `"graphBuildCacheSize": 5000`
- *Global setting*: `arcadedb.vectorIndex.graphBuildCacheSize`
- *Recommended*: 10,000 for 768-dim vectors (~30 MB RAM), scale based on dimensionality

*Mutations Before Rebuild* (`mutationsBeforeRebuild`)

Number of mutations (inserts/updates/deletes) before rebuilding the HNSW graph index. Higher values reduce rebuild cost but may return slightly stale results.

- *Default*: `100` (balanced)
- *Per-index metadata*: `"mutationsBeforeRebuild": 200`
- *Global setting*: `arcadedb.vectorIndex.mutationsBeforeRebuild`
- *Recommended*: 50-200 for read-heavy workloads, 200-500 for write-heavy workloads

====== Memory Tuning Examples

*Maximum Memory Efficiency* (Edge deployments, resource-constrained environments):

[source,sql]
----
-- Configure globally for all vector indexes
ALTER DATABASE SETTING arcadedb.vectorIndex.locationCacheSize = 50000;
ALTER DATABASE SETTING arcadedb.vectorIndex.graphBuildCacheSize = 5000;

-- Or configure per-index
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 768,
  "similarity": "COSINE",
  "maxConnections": 8,
  "beamWidth": 100,
  "locationCacheSize": 50000,        -- Limit location cache: ~2.8 MB
  "graphBuildCacheSize": 5000,       -- Limit graph building: ~15 MB peak
  "mutationsBeforeRebuild": 150      -- Moderate rebuild frequency
};
----

*Memory Impact*: For 1M vectors with 768 dimensions:
- Location cache: 50K entries = ~2.8 MB (vs ~56 MB unlimited)
- Graph build cache: 5K vectors = ~15 MB (vs ~3 GB unlimited)
- *Total savings: ~98.5% memory reduction during graph building*

*Balanced Configuration* (Production workloads with moderate scale):

[source,sql]
----
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 768,
  "similarity": "COSINE",
  "maxConnections": 16,
  "beamWidth": 100,
  "locationCacheSize": 100000,       -- Balance memory vs performance
  "graphBuildCacheSize": 10000,      -- Default (30 MB for 768-dim)
  "mutationsBeforeRebuild": 100      -- Standard rebuild frequency
};
----

*Memory Impact*: For 1M vectors with 768 dimensions:
- Location cache: 100K entries = ~5.6 MB (90% reduction)
- Graph build cache: 10K vectors = ~30 MB (99% reduction)

*Maximum Performance* (Unlimited memory, prioritize speed):

[source,sql]
----
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 768,
  "similarity": "COSINE",
  "maxConnections": 32,
  "beamWidth": 200,
  "locationCacheSize": -1,           -- Unlimited cache (no eviction)
  "graphBuildCacheSize": 50000,      -- Large cache: ~150 MB for 768-dim
  "mutationsBeforeRebuild": 50       -- Frequent rebuilds for freshness
};
----

*Performance Impact*: Best query performance with highest memory usage.

====== Performance Tuning Examples

*Write-Heavy Workload* (High ingestion rate, acceptable search latency):

[source,sql]
----
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 768,
  "similarity": "COSINE",
  "maxConnections": 12,
  "beamWidth": 80,
  "locationCacheSize": 100000,
  "graphBuildCacheSize": 10000,
  "mutationsBeforeRebuild": 300      -- Reduce rebuild frequency for write throughput
};
----

*Read-Heavy Workload* (Search-intensive, prioritize freshness):

[source,sql]
----
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 768,
  "similarity": "COSINE",
  "maxConnections": 24,
  "beamWidth": 150,
  "locationCacheSize": 200000,       -- Larger cache for hot vectors
  "graphBuildCacheSize": 10000,
  "mutationsBeforeRebuild": 50       -- Frequent rebuilds for fresh results
};
----

====== Global Configuration via SQL

Set global defaults for all vector indexes in the database:

[source,sql]
----
-- Configure global defaults
ALTER DATABASE SETTING arcadedb.vectorIndex.locationCacheSize = 100000;
ALTER DATABASE SETTING arcadedb.vectorIndex.graphBuildCacheSize = 10000;
ALTER DATABASE SETTING arcadedb.vectorIndex.mutationsBeforeRebuild = 100;

-- View current settings
SELECT FROM information_schema.settings
WHERE name LIKE 'arcadedb.vectorIndex.%';
----

Per-index metadata settings override global defaults. Use global settings to establish baseline memory limits across all indexes, then tune individual indexes as needed.

====== Memory Consumption Reference

For 1 million vectors with 768 dimensions:

[cols="2,1,1,1", options="header"]
|===
|Configuration |Location Cache |Graph Build Cache |Total Peak Memory

|Unlimited (legacy)
|~56 MB
|~3 GB
|~3.06 GB

|Recommended (100K/10K)
|~5.6 MB
|~30 MB
|~35.6 MB

|Memory Constrained (50K/5K)
|~2.8 MB
|~15 MB
|~17.8 MB

|Savings vs Unlimited
|90-95%
|99%
|98.8%
|===

*Formula for Graph Build Cache*:
----
RAM (MB) = cacheSize × (dimensions × 4 + 64) / 1024 / 1024
----

*Example*:
- 10,000 vectors × 768 dimensions = 10,000 × (768 × 4 + 64) / 1024 / 1024 ≈ 30 MB
- 10,000 vectors × 1536 dimensions = 10,000 × (1536 × 4 + 64) / 1024 / 1024 ≈ 59 MB

====== Best Practices for Tuning

1. *Start with Defaults*: Default settings (locationCacheSize=-1, graphBuildCacheSize=10000, mutationsBeforeRebuild=100) work well for most use cases under 100K vectors.

2. *Monitor Memory Usage*: For large-scale deployments (1M+ vectors), set explicit limits to prevent unbounded growth.

3. *Scale Graph Build Cache with Dimensions*: Higher dimensionality requires proportionally more memory during graph building.

4. *Balance Rebuild Frequency*: Lower `mutationsBeforeRebuild` provides fresher search results but increases CPU cost. Higher values improve write throughput at the cost of search staleness.

5. *Per-Index Tuning*: Use global settings as baseline, then override for specific indexes based on workload characteristics.

6. *Cache Hit Monitoring*: If queries become noticeably slower after setting `locationCacheSize` limits, increase the cache size or use `-1` (unlimited) for that index.

7. *Write vs Read Trade-offs*: Write-heavy workloads benefit from higher `mutationsBeforeRebuild` (200-500), while read-heavy workloads benefit from lower values (50-100).

===== Querying Vector Indexes with SQL

Use the `vectorNeighbors()` function to perform similarity searches:

====== Basic Similarity Search

Find the 10 most similar documents to a query vector:

[source,sql]
----
SELECT FROM Document
WHERE vectorNeighbors('embedding', $queryVector, 10) > 0.8;
----

The `vectorNeighbors()` function returns similarity scores, allowing you to filter results by minimum similarity threshold. Use named parameters (e.g., `$queryVector`) instead of hardcoded vectors for real-world applications.

====== Combining with Other Filters

Combine vector search with traditional SQL filters:

[source,sql]
----
-- Find similar documents from a specific source
SELECT FROM Document
WHERE source = 'wikipedia'
  AND vectorNeighbors('embedding', $queryVector, 10) > 0.8
ORDER BY vectorNeighbors('embedding', $queryVector, 10) DESC
LIMIT 5;
----

====== Multi-Modal Vector Search

Create and query multiple vector indexes for multi-modal data:

[source,sql]
----
-- Create multi-modal schema
CREATE VERTEX TYPE MultiModalRecord;
CREATE PROPERTY MultiModalRecord.imageEmbedding LIST OF FLOAT;
CREATE PROPERTY MultiModalRecord.textEmbedding LIST OF FLOAT;

-- Create separate indexes
CREATE INDEX ON MultiModalRecord (imageEmbedding) LSM_VECTOR METADATA {
  dimensions: 512,
  similarity: 'COSINE'
};

CREATE INDEX ON MultiModalRecord (textEmbedding) LSM_VECTOR METADATA {
  dimensions: 768,
  similarity: 'COSINE'
};

-- Query both modalities
SELECT FROM MultiModalRecord
WHERE vectorNeighbors('imageEmbedding', [0.1, 0.2, ...], 5) > 0.8
   OR vectorNeighbors('textEmbedding', [0.2, 0.3, ...], 5) > 0.8;
----

====== Retrieving Neighbor Details

Get detailed information about nearest neighbors:

[source,sql]
----
-- Returns array of objects with distance and keys
SELECT vectorNeighbors('Document[embedding]', $queryVector, 10) AS neighbors;
----

*Note*: When using `vectorNeighbors()` in a `SELECT` clause to retrieve neighbor details, pass the full index name (e.g., `'Document[embedding]'`) as the first argument. In `WHERE` clauses, use the property name (e.g., `'embedding'`) instead.

===== Using the Java API

For programmatic control and embedded applications, use the Java API to create and manage vector indexes.

====== Creating LSMVectorIndex Programmatically

[source,java]
----
import com.arcadedb.database.Database;
import com.arcadedb.schema.Schema;
import com.arcadedb.schema.Type;
import com.arcadedb.index.lsm.LSMVectorIndex;
import com.arcadedb.index.lsm.LSMVectorIndexBuilder;
import com.arcadedb.index.vector.VectorSimilarityFunction;

// Get or create schema
final Schema schema = database.getSchema();
if (!schema.existsType("Document")) {
  schema.createVertexType("Document");
}

// Create vector property
if (!schema.existsProperty("Document", "embedding")) {
  schema.createProperty("Document", "embedding", Type.ARRAY_OF_FLOATS);
}

// Create LSMVectorIndex with builder pattern
final LSMVectorIndexBuilder builder = new LSMVectorIndexBuilder(
    database,
    "Document",
    new String[]{"embedding"})
    .withDimensions(768)
    .withSimilarity(VectorSimilarityFunction.COSINE)
    .withMaxConnections(16)
    .withBeamWidth(100)
    .withIdProperty("id");

final LSMVectorIndex index = builder.create();
----

====== Adding Vectors to the Index

[source,java]
----
// Get existing index
final LSMVectorIndex index = (LSMVectorIndex) database.getSchema()
    .getIndexByName("Document[embedding]");

// Add vectors with callback
index.addAll(embeddings, (vertex, item, total) -> {
  // Optional callback for handling vertex creation
  // Useful for cascading operations like creating relationships
  if (vertex != null) {
    // Create relationships, update metadata, etc.
    System.out.println("Indexed vertex " + vertex.getIdentity() +
                      " (" + item + "/" + total + ")");
  }
});
----

The callback in the `addAll()` method is useful when you have a graph structure connected to the indexed vertices. For example, when indexing a book, you might calculate embeddings per statement and then create relationships between statements and paragraphs.

====== Configuring from JSON Metadata

Load configuration from JSON metadata:

[source,java]
----
import com.arcadedb.utility.JSONObject;

final JSONObject metadata = new JSONObject()
    .put("dimensions", 768)
    .put("similarity", "COSINE")
    .put("maxConnections", 16)
    .put("beamWidth", 100)
    .put("idPropertyName", "id");

final LSMVectorIndexBuilder builder = new LSMVectorIndexBuilder(
    database,
    "Document",
    new String[]{"embedding"})
    .fromMetadata(metadata);

final LSMVectorIndex index = builder.create();
----

====== Querying Vectors from Java

[source,java]
----
import com.arcadedb.query.sql.executor.ResultSet;

// Define an example query vector. Replace with your actual vector.
float[] queryVector = new float[] {0.1f, 0.2f, 0.3f}; // Vector must match index dimensions

// Perform similarity search using SQL
final ResultSet resultSet = database.query("sql",
    "SELECT FROM Document " +
    "WHERE vectorNeighbors('embedding', ?, 10) > 0.8 " +
    "LIMIT 5",
    queryVector);

while (resultSet.hasNext()) {
  final Result result = resultSet.next();
  System.out.println("Similar document: " + result.toJSON());
}
----

====== Transaction Support

LSMVectorIndex fully supports transactions with automatic persistence:

[source,java]
----
database.transaction(() -> {
  // Create vertices with embeddings
  final MutableVertex vertex = database.newVertex("Document");
  vertex.set("content", "Sample text");

  // In a real application, this vector would be generated by an embedding model
  // and should match the dimensions of the index.
  float[] embeddingVector = new float[] {0.5f, 0.6f, 0.7f};
  vertex.set("embedding", embeddingVector);
  vertex.save();

  // Index is automatically updated on transaction commit
});
----

===== Migration from HnswVectorIndexRAM

If you're migrating from the older HnswVectorIndexRAM approach, note the following differences:

[cols="1,1,1", options="header"]
|===
|Feature |HnswVectorIndexRAM |LSMVectorIndex

|Persistence
|Requires explicit conversion
|Automatic with transactions

|SQL Support
|Limited
|Full SQL CREATE INDEX and queries

|Transaction Support
|Manual management
|Automatic ACID compliance

|Compaction
|Manual
|Automatic

|Recommended For
|Bulk loading scenarios
|All production use cases
|===

====== Legacy Bulk Loading Pattern

For backwards compatibility, the HnswVectorIndexRAM bulk loading pattern is still available for initial large-scale imports:

[source,java]
----
import com.arcadedb.index.vector.HnswVectorIndexRAM;
import com.arcadedb.index.vector.VectorSimilarityFunction;
import com.arcadedb.index.vector.Item;
import com.arcadedb.schema.Type;
import java.util.Collection;
import java.util.List;

// For bulk loading only - use LSMVectorIndex for production
String indexName = "Document[embedding]";
if (!database.getSchema().existsIndex(indexName)) {
  // Define parameters for the index
  int dimensions = 768;
  VectorSimilarityFunction distanceFunction = VectorSimilarityFunction.COSINE;
  int m = 16;
  int ef = 200;
  int efConstruction = 200;
  // Example embeddings. In a real scenario, this would be a large collection.
  Collection<Item<Object, float[]>> embeddings = List.of(
      new Item<>("doc1", new float[]{0.1f, 0.2f}),
      new Item<>("doc2", new float[]{0.3f, 0.4f})
  );

  // Step 1: Load into RAM-based index
  final HnswVectorIndexRAM<Object, float[], Item<Object, float[]>, Float> hnswIndex =
      HnswVectorIndexRAM.newBuilder(dimensions, distanceFunction, 100_000)
          .withM(m)
          .withEf(ef)
          .withEfConstruction(efConstruction)
          .build();

  hnswIndex.addAll(embeddings,
                   Runtime.getRuntime().availableProcessors(), null);

  // Step 2: Create persistent index
  hnswIndex.createPersistentIndex(database)
      .withVertexType("Document")
      .withEdgeType("Proximity")
      .withVectorProperty("embedding", Type.ARRAY_OF_FLOATS)
      .withIdProperty("id")
      .create();
}
----

NOTE: For most use cases, directly creating an LSMVectorIndex via SQL or the Java API is simpler and provides better transaction support. The HnswVectorIndexRAM approach is only recommended for specific bulk loading scenarios with millions of vectors.

===== Best Practices

1. *Choose the Right Similarity Function*: Use COSINE for normalized embeddings (most common), DOT_PRODUCT for performance with normalized vectors, or EUCLIDEAN for spatial data.

2. *Normalize Your Vectors*: For COSINE and DOT_PRODUCT similarity, ensure vectors are normalized to unit length for best results.

3. *Tune Performance Parameters*: Start with defaults (maxConnections=16, beamWidth=100) and increase for better recall if needed.

4. *Use Transactions*: Always insert vectors within transactions for data consistency and automatic index updates.

5. *Batch Insertions*: For large datasets, batch your insertions in reasonably-sized transactions (1000-10000 records) for optimal performance.

6. *Monitor Index Size*: Vector indexes can be large. Monitor disk usage and consider the dimensions parameter carefully.

7. *SQL for Simplicity*: Prefer SQL for index creation and queries unless you need programmatic control.

===== Common Use Cases

====== Semantic Document Search

[source,sql]
----
-- Create index for document embeddings
CREATE VERTEX TYPE Document;
CREATE PROPERTY Document.content STRING;
CREATE PROPERTY Document.embedding LIST OF FLOAT;
CREATE INDEX ON Document (embedding) LSM_VECTOR METADATA {
  "dimensions": 384,
  "similarity": "COSINE"
};

-- Query for similar documents
SELECT content FROM Document
WHERE vectorNeighbors('embedding', $queryEmbedding, 10) > 0.75
ORDER BY vectorNeighbors('embedding', $queryEmbedding, 10) DESC;
----

====== Image Similarity Search

[source,sql]
----
-- Create index for image feature vectors
CREATE VERTEX TYPE Image;
CREATE PROPERTY Image.url STRING;
CREATE PROPERTY Image.features LIST OF FLOAT;
CREATE INDEX ON Image (features) LSM_VECTOR METADATA {
  dimensions: 512,
  similarity: 'COSINE'
};

-- Find similar images
SELECT url FROM Image
WHERE vectorNeighbors('features', $imageFeatures, 5) > 0.8;
----

====== Recommendation System

[source,sql]
----
-- Create index for user/item embeddings
CREATE VERTEX TYPE Product;
CREATE PROPERTY Product.embedding LIST OF FLOAT;
CREATE INDEX ON Product (embedding) LSM_VECTOR METADATA {
  "dimensions": 128,
  "similarity": "COSINE"
};

-- Find similar products for recommendations
SELECT * FROM Product
WHERE category = $category
  AND vectorNeighbors('embedding', $userPreferenceVector, 20) > 0.7
ORDER BY vectorNeighbors('embedding', $userPreferenceVector, 20) DESC
LIMIT 10;
----

For more information, see:

* <<indexes, Indexes>>
* <<sql-create-index, CREATE INDEX>>
* <<vector-neighbors, vectorNeighbors()>>
